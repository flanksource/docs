## Mapping

Custom scrapers require you to define the `id` and `type` for each scraped item. For example, when you scrape a file containing a JSON array, where each array element represents a config item, you must specify the `id` and `type` for those items.
You can achieve this by using mappings in your custom scraper configuration.

<Fields
  rows={[
    {
      field: 'items',
      description: 'A JSONPath expression to use to extract individual items from the resource. Items are extracted first and then the ID, Name, Type and transformations are applied for each item.',
      scheme: 'jsonpath',
    },
    {
      field: 'id',
      description: 'A static value or JSONPath expression to use as the ID for the resource.',
      scheme: 'jsonpathorstring',
      required: true
    },
    {
      field: 'type',
      description: 'A static value or JSONPath expression to use as the type for the resource.',
      scheme: 'jsonpathorstring',
      required: true
    },
    {
      field: 'class',
      description: 'A static value or JSONPath expression to use as the class for the resource.',
      scheme: 'jsonpathorstring'
    },
    {
      field: 'name',
      description: 'A static value or JSONPath expression to use as the name for the resource.',
      scheme: 'jsonpathorstring',
      required: true
    },
    {
      field: 'description',
      description: 'A static value or JSONPath expression to use as the description for the resource.',
      scheme: 'jsonpathorstring'
    },
    {
      field: 'status',
      description: 'A static value or JSONPath expression to use as the status of the config item.',
      scheme: 'jsonpathorstring'
    },
    {
      field: 'health',
      description: 'A static value or JSONPath expression to use as the health of the config item.',
      scheme: 'jsonpathorstring'
    },
    {
      field: 'format',
      description: 'Format of config item, defaults to JSON, available options are JSON, properties. See [Formats](#formats)',
      scheme: 'string'
    },
    {
      field: 'createFields',
      description: 'A list of JSONPath expressions used to identify the created time of the config. If multiple fields are specified, the first non-empty value will be used.',
      scheme: '[]jsonpath'
    },
    {
      field: 'deleteFields',
      description: 'A list of JSONPath expressions used to identify the deleted time of the config. If multiple fields are specified, the first non-empty value will be used.',
      scheme: '[]jsonpath'
    },
    {
      field: 'timestampFormat',
      description: 'A Go time format string used to parse timestamps in createFields and deleteFields. _(Default: RFC3339)_',
      scheme: 'string'
    }
  ]}
/>

## Formats

### JSON

The scraper stores config items as `jsonb` fields in PostgreSQL.

Resource providers typically return the JSON used. e.g. `kubectl get -o json` or `aws --output=json`.

When you display the config, the UI automatically converts the JSON data to YAML for improved readability.

### XML / Properties

The scraper stores non-JSON files as JSON using:

```yaml
{ 'format': 'xml', 'content': '<root>..</root>' }
```

You can still access non-JSON content in scripts using `config.content`.

The UI formats and renders XML appropriately.

## Extracting Changes & Access Logs

Custom scrapers ingest changes & access logs from external systems when you enable the `full` option.

Every single config is expected to have at these 3 top-level fields

- `config`
- `changes`
- `access_logs`

:::note info
They could have more fields or even missing some of these fields.
The point is that only these fields are extracted.
:::

Consider a file that contains the following json data.

```json title=fixtures/data/car.json {3,6,13}
{
  "reg_no": "A123",
  "config": {
    "meta": "this is the actual config that'll be stored."
  },
  "changes": [
    {
      "action": "drive",
      "summary": "car color changed to blue",
      "unrelated_stuff": 123
    }
  ],
  "access_logs": [
    {
      "config_id": "99024949-9118-4dcb-a3a0-b8f1536bebd0",
      "external_user_id": "a3542241-4750-11f0-8000-e0146ce375e6",
      "created_at": "2025-01-01"
    },
    {
      "config_id": "9d9e51a7-6956-413e-a07e-a6aeb3f4877f",
      "external_user_id": "a5c2e8e3-4750-11f0-8000-f4eaacabd632",
      "created_at": "2025-01-02"
    }
  ]
}
```

A regular scraper saves the entire json as a config.
However, with the `full` option, the scraper extracts the config, changes and access logs.

```yaml {6}
apiVersion: configs.flanksource.com/v1
kind: ScrapeConfig
metadata:
  name: file-scraper
spec:
  full: true
  file:
    - type: Car
      id: $.reg_no
      paths:
        - fixtures/data/car_changes.json
```

The resulting config is:

```json
{
  "meta": "this is the actual config that'll be stored."
}
```

and the scraper records the following new config change on that config:

```json
{
  "action": "drive",
  "summary": "car color changed to blue",
  "unrelated_stuff": 123
}
```

and the access logs will be saved to

```json
[
  {
    "config_id": "99024949-9118-4dcb-a3a0-b8f1536bebd0",
    "external_user_id": "a3542241-4750-11f0-8000-e0146ce375e6",
    "created_at": "2025-01-01"
  },
  {
    "config_id": "9d9e51a7-6956-413e-a07e-a6aeb3f4877f",
    "external_user_id": "a5c2e8e3-4750-11f0-8000-f4eaacabd632",
    "created_at": "2025-01-02"
  }
]
```
