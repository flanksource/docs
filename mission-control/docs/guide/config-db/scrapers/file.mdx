---
title: File
sidebar_custom_props:
  icon: pepicons-pencil:file-loop

---


import Custom from './_custom.md'


The `file` scraper is used to create config items from files in a local folder (or git). This can be used to track changes in files like `/etc/hosts` or `/etc/passwd`, or for service metadata stored in git.

See [Kubernetes Files](./kubernetes-file) for scraping files inside running kubernetes pods.

```yaml title='file-scraper.yaml' file=<rootDir>/modules/config-db/fixtures/file-git.yaml
apiVersion: configs.flanksource.com/v1
kind: ScrapeConfig
metadata:
  name: file-scraper
spec:
  file:
    - type: $.Config.InstanceType
      id: $.Config.InstanceId
      path:
        - config*.json
        - test*.json
```


## Scraper

| Field       | Description                                                                        | Scheme                                       | Required |
| ----------- | ---------------------------------------------------------------------------------- | -------------------------------------------- | -------- |
| `schedule`  | Specify the interval to scrape in cron format. Defaults to every 60 minutes.       | `string`                                     |          |
| `full`      | Set to `true` to extract changes from scraped configurations. Defaults to `false`. | `bool`                                       |          |
| `retention` | Settings for retaining changes, analysis and scraped items                         | [`Retention`](/guide/config-db/concepts/retention) |          |
| `file`      | Specifies the list of File configurations to scrape.                               | [`[]File`](#file)                          |          |

### File


<CustomScraper rows={[

  {
    "field": "url",
    "description": "Specify URL e.g github repository containing the configuration(s)",
    "scheme": "string"
  },
  {
    "field": "paths",
    "description": "Specify paths to configuration(s) for scraping",
    "scheme": "[]glob",
    "required": "true"
  },

]}/>


<Custom/>

