---
title: Logs
sidebar_position: 13
sidebar_custom_props:
  icon: logs
---

# <Icon name="logs"/> Logs

<!-- Source: modules/config-db/api/v1/logs.go#Logs -->

The Logs scraper queries log aggregation systems to extract configuration changes from log entries. It supports multiple log backends including Loki, GCP Cloud Logging, OpenSearch, and BigQuery. This allows you to create configuration items and track changes based on log data.

## Use Cases

- **Application Configuration Changes**: Track config reloads and updates from application logs
- **Deployment Tracking**: Monitor deployment events from CI/CD pipeline logs
- **Error Analysis**: Create configuration items from error patterns in logs
- **Audit Trail**: Track security and compliance events from audit logs
- **Performance Monitoring**: Extract performance metrics as configuration changes

```yaml title="logs-scraper.yaml" file=<rootDir>/modules/config-db/fixtures/logs-app-config-changes.yaml
```

| Field       | Description                                                                  | Scheme                                             | Required |
| ----------- | ---------------------------------------------------------------------------- | -------------------------------------------------- | -------- |
| `schedule`  | Specify the interval to scrape in cron format. Defaults to every 60 minutes. | [Cron](/docs/reference/types#cron)                      |          |
| `retention` | Settings for retaining changes, analysis and scraped items                   | [`Retention`](/docs/guide/config-db/concepts/retention) |          |
| `logs`      | Specifies the list of log configurations to scrape.                          | [`[]Logs`](#logs)                                  | `true`   |

### Logs

<Fields rows={[
  {
    field: "fieldMapping.timestamp",
    description: "Source field names containing timestamp data. The scraper tries each field in order until it finds a non-empty value. Common values: `@timestamp`, `timestamp`, `time`, `date`",
    scheme: "[]string"
  },
  {
    field: "fieldMapping.severity",
    description: "Source field names containing log level/severity. Used to categorize log entries. Common values: `level`, `severity`, `log_level`, `priority`",
    scheme: "[]string"
  },
  {
    field: "fieldMapping.message",
    description: "Source field names containing the main log message content. Common values: `message`, `msg`, `log`, `text`, `body`",
    scheme: "[]string"
  },
  {
    field: "fieldMapping.id",
    description: "Source field names containing unique identifiers for deduplication. Common values: `id`, `event_id`, `trace_id`, `request_id`",
    scheme: "[]string"
  },
  {
    priority: 1,
    field: "bigQuery",
    description: "BigQuery configuration for log scraping",
    scheme: "[BigQuery](#bigquery)"
  },
  {
        priority: 1,

    field: "gcpCloudLogging",
    description: "GCP Cloud Logging configuration",
    scheme: "[GCPCloudLogging](#gcpcloudlogging)"
  },
  {
        priority: 1,

    field: "loki",
    description: "Loki configuration for log scraping",
    scheme: "[Loki](#loki)"
  },
  {
        priority: 1,

    field: "openSearch",
    description: "OpenSearch configuration for log scraping",
    scheme: "[OpenSearch](#opensearch)"
  }
]} />

## Field Mapping

Different log systems use different field names for the same data. For example:
- **Timestamp**: Elasticsearch uses `@timestamp`, Loki uses `ts`, CloudWatch uses `timestamp`
- **Message**: Some systems use `message`, others use `msg`, `log`, or `text`
- **Severity**: Could be `level`, `severity`, `log_level`, or `priority`

Field mapping normalizes these differences so your transform expressions work consistently regardless of the log source.

### How It Works

When you specify multiple field names, the scraper tries each one in order and uses the first non-empty value:

```yaml
fieldMapping:
  timestamp: ['@timestamp', 'timestamp', 'time']  # Try @timestamp first, then timestamp, then time
  message: ['message', 'msg', 'log']
  severity: ['level', 'severity']
  id: ['trace_id', 'request_id', 'event_id']
```

### When to Use Field Mapping

Use field mapping when:
- Your logs come from multiple sources with different schemas
- You're migrating between log systems and field names changed
- Third-party applications use non-standard field names
- You want transforms to be portable across different backends

<details summary="Example: Normalizing ELK and Loki logs">

```yaml
apiVersion: configs.flanksource.com/v1
kind: ScrapeConfig
metadata:
  name: unified-app-logs
spec:
  logs:
    # OpenSearch/Elasticsearch logs use @timestamp and message
    - openSearch:
        url: https://elasticsearch:9200
        index: app-logs-*
      fieldMapping:
        timestamp: ['@timestamp']
        message: ['message']
        severity: ['level', 'log.level']
        id: ['trace.id', 'request_id']

    # Loki logs use different field names
    - loki:
        url: http://loki:3100
        query: '{app="myservice"}'
      fieldMapping:
        timestamp: ['ts', 'timestamp']
        message: ['line', 'msg']
        severity: ['level', 'detected_level']
        id: ['traceID']
```

</details>

### BigQuery

<Fields rows={[
  {
    field: "project",
    description: "GCP project ID containing the BigQuery dataset",
    scheme: "string",
    required: true
  },
  {
    field: "query",
    description: "SQL query to execute against BigQuery",
    scheme: "string",
    required: true
  },
  {
    field: "credentials",
    description: "GCP service account credentials",
    scheme: "[EnvVar](/docs/reference/env-var)"
  }
]} />

<details summary="Example">

```yaml title="bigquery-github-commits.yaml" file=<rootDir>/modules/config-db/fixtures/bigquery-logs.yaml
```

</details>

### GCPCloudLogging

<Fields rows={[
  {
    field: "project",
    description: "GCP project ID",
    scheme: "string",
    required: true
  },
  {
    field: "filter",
    description: "Cloud Logging filter query",
    scheme: "string"
  },
  {
    field: "orderBy",
    description: "Field to order results by",
    scheme: "string"
  },
  {
    field: "pageSize",
    description: "Number of entries per page",
    scheme: "int"
  },
  {
    field: "credentials",
    description: "GCP service account credentials",
    scheme: "[EnvVar](/docs/reference/env-var)"
  }
]} />

<details summary="Example">

```yaml
apiVersion: configs.flanksource.com/v1
kind: ScrapeConfig
metadata:
  name: gcp-audit-logs
spec:
  logs:
    - gcpCloudLogging:
        project: my-gcp-project
        filter: |
          protoPayload.serviceName="compute.googleapis.com"
          protoPayload.methodName:"compute.instances"
        orderBy: timestamp desc
        pageSize: 100
      transform:
        expr: |
          dyn(config.logs).map(line, {
            "changes": [{
              "change_type": "GCPResourceChange",
              "external_id": line.resource.labels.instance_id,
              "config_type": "GCP::Instance",
              "created_at": line.timestamp,
              "summary": line.protoPayload.methodName
            }]
          }).toJSON()
```

</details>

### Loki

<Fields rows={[
  {
    field: "url",
    description: "Loki server URL",
    scheme: "string",
    required: true
  },
  {
    field: "query",
    description: "LogQL query to execute",
    scheme: "string",
    required: true
  },
  {
    field: "start",
    description: "Start time for the query (e.g., '24h', '7d')",
    scheme: "string"
  },
  {
    field: "end",
    description: "End time for the query",
    scheme: "string"
  },
  {
    field: "limit",
    description: "Maximum number of log entries to return",
    scheme: "string"
  },
  {
    field: "username",
    description: "Basic auth username",
    scheme: "[EnvVar](/docs/reference/env-var)"
  },
  {
    field: "password",
    description: "Basic auth password",
    scheme: "[EnvVar](/docs/reference/env-var)"
  }
]} />

<details summary="Example">

```yaml title="loki-config-changes.yaml" file=<rootDir>/modules/config-db/fixtures/logs-app-config-changes.yaml
```

</details>

### OpenSearch

<Fields rows={[
  {
    field: "url",
    description: "OpenSearch cluster URL",
    scheme: "string",
    required: true
  },
  {
    field: "index",
    description: "Index name or pattern",
    scheme: "string",
    required: true
  },
  {
    field: "query",
    description: "OpenSearch query DSL",
    scheme: "string"
  },
  {
    field: "size",
    description: "Number of results to return",
    scheme: "int"
  },
  {
    field: "username",
    description: "Basic auth username",
    scheme: "[EnvVar](/docs/reference/env-var)"
  },
  {
    field: "password",
    description: "Basic auth password",
    scheme: "[EnvVar](/docs/reference/env-var)"
  }
]} />

<details summary="Example">

```yaml
apiVersion: configs.flanksource.com/v1
kind: ScrapeConfig
metadata:
  name: opensearch-security-events
spec:
  logs:
    - openSearch:
        url: https://opensearch-cluster:9200
        index: security-logs-*
        query: |
          {
            "query": {
              "bool": {
                "must": [
                  {"term": {"event_type": "authentication"}},
                  {"range": {"@timestamp": {"gte": "now-1h"}}}
                ]
              }
            }
          }
        size: 1000
        username:
          valueFrom:
            secretKeyRef:
              name: opensearch-creds
              key: username
        password:
          valueFrom:
            secretKeyRef:
              name: opensearch-creds
              key: password
      fieldMapping:
        timestamp: ['@timestamp', 'timestamp']
        message: ['message', 'event_description']
        severity: ['severity', 'log_level']
        id: ['event_id', 'transaction_id']
```

</details>
